1
00:00:00,000 --> 00:00:02,200
 what's up folks. In this video, we're going to talk about

2
00:00:02,200 --> 00:00:05,920
 building agent workflows in eight levels of complexity. This is a

3
00:00:05,920 --> 00:00:09,760
 follow up to one of my best videos from my channel, called

4
00:00:09,760 --> 00:00:12,720
 building agents in three levels of complexity. And today, we're

5
00:00:12,720 --> 00:00:16,680
 going to talk about how to go from a simple LMM call, all the way

6
00:00:16,680 --> 00:00:20,720
 up to an agent workflow that uses an agent as a step. We're going

7
00:00:20,720 --> 00:00:24,560
 to talk through the papers and the a little bit of the theory in a

8
00:00:24,560 --> 00:00:27,000
 lot of the practice, right? Everything is going to be from

9
00:00:27,000 --> 00:00:30,200
 scratch. Meaning we are they're going to use the basic and lame

10
00:00:30,200 --> 00:00:33,440
 APIs, or we're just going to build stuff ourselves in pure

11
00:00:33,440 --> 00:00:37,120
 Python. All right. So we're going to start easy, we're going to

12
00:00:37,120 --> 00:00:42,480
 set up our environment variable for open API key. And we're going

13
00:00:42,480 --> 00:00:46,240
 to run this. And now we're going to basically just write a

14
00:00:46,240 --> 00:00:48,760
 simple LMM call. And that's super easy, right? We just have

15
00:00:48,760 --> 00:00:52,880
 to import the open API, set up our client. And then we're going

16
00:00:52,880 --> 00:00:56,200
 to write a little function. And I'm going to name the functions

17
00:00:56,240 --> 00:00:59,040
 like level one, level two, level three to like organize our

18
00:00:59,040 --> 00:01:04,120
 thoughts. And the first one's called level one. And it's the

19
00:01:04,120 --> 00:01:08,640
 basic LMM call, which essentially just calls the responses API

20
00:01:08,640 --> 00:01:12,840
 from open AI, uses the GPT five mini model, sends a simple

21
00:01:12,840 --> 00:01:17,440
 prompt and gets a response back. Pretty basic. So now we're

22
00:01:17,440 --> 00:01:20,640
 going to call it like what is an agent workflow. And when we

23
00:01:20,640 --> 00:01:23,960
 run it, we'll take a few seconds. And we'll just provide us with

24
00:01:23,960 --> 00:01:27,920
 the response, pretty basic simple stuff. We specify the model,

25
00:01:27,920 --> 00:01:31,240
 the input, and that's it. Right, we can use this to do things

26
00:01:31,240 --> 00:01:35,240
 like summarize, extract a little bit of information. And we're

27
00:01:35,240 --> 00:01:40,960
 limited by the prompting mechanics of the specific API. So

28
00:01:40,960 --> 00:01:43,440
 we're just going to prompt and give responses back. So it's

29
00:01:43,440 --> 00:01:48,960
 text goes in, text comes out. Okay, great. However, now when we

30
00:01:48,960 --> 00:01:52,520
 go to level two, now we can start thinking about how can we

31
00:01:52,520 --> 00:01:55,360
 chain these LMM costs to make something a little bit more

32
00:01:55,360 --> 00:02:00,160
 powerful, right? And a very cool resource for this topic is

33
00:02:00,160 --> 00:02:04,320
 building effective agents by anthropic, where they talk about

34
00:02:04,320 --> 00:02:08,040
 workflow agents went to use them, how they work, and they go

35
00:02:08,040 --> 00:02:11,600
 from scratch. And this article definitely inspired my desire

36
00:02:11,600 --> 00:02:15,160
 to do this video that I'm doing right now. So go check it out.

37
00:02:15,160 --> 00:02:19,520
 All right, so chaining LMM calls is super easy. All we got to

38
00:02:19,520 --> 00:02:22,000
 do is essentially what we're going to do is we're going to set

39
00:02:22,000 --> 00:02:26,240
 up a function that does the LLM call, so takes in some input

40
00:02:26,240 --> 00:02:31,400
 and provides some output. And this calls the opening API like we

41
00:02:31,400 --> 00:02:36,000
 did before, use the GPT five mini model and sends a prompt and

42
00:02:36,000 --> 00:02:40,840
 gets a response back easy. However, the level true is all

43
00:02:40,840 --> 00:02:45,800
 about chaining as many LLM calls as we want. So for that, what

44
00:02:45,800 --> 00:02:48,200
 we're going to do is we're going to take we're going to start

45
00:02:48,200 --> 00:02:51,640
 with an input in a list of prompts that we want to chain

46
00:02:51,640 --> 00:02:55,120
 together. Then what we're going to do is we're going to loop

47
00:02:55,120 --> 00:03:00,760
 over these prompts. And for each prompt, we're going to take a

48
00:03:00,760 --> 00:03:05,520
 result of calling the making a call to the LLM call function

49
00:03:05,520 --> 00:03:10,960
 with that prompt on and save the result as an input for the

50
00:03:10,960 --> 00:03:14,560
 next call. So that means that we start with the result as the

51
00:03:14,560 --> 00:03:19,080
 input, right? And then we call the first prompt. And then the

52
00:03:19,080 --> 00:03:22,840
 next one is going to take in the result of the previous one as

53
00:03:22,840 --> 00:03:26,080
 the input for the next. And we're going to do that for as many

54
00:03:26,080 --> 00:03:28,640
 prompts as we have on the list of prompts that we're going to

55
00:03:28,640 --> 00:03:31,440
 give this function as an input. And then we're going to print

56
00:03:31,440 --> 00:03:35,400
 that out. And that's pretty much what it is. And for the

57
00:03:35,400 --> 00:03:38,680
 example usage, I'm putting here an input topic like a Gentic

58
00:03:38,680 --> 00:03:41,640
 workflow. And then the prompt is first, we're going to create a

59
00:03:41,640 --> 00:03:44,600
 three bullet point essay plan for this topic. And then we're

60
00:03:44,600 --> 00:03:48,040
 going to write the essay following the plan strictly. All

61
00:03:48,040 --> 00:03:54,000
 right. And when we call this, right, so I can call it with the

62
00:03:54,000 --> 00:03:58,520
 input and the list of prompts, this is what happens. So what

63
00:03:58,520 --> 00:04:00,440
 we're going to see is that first, we're going to see the

64
00:04:00,440 --> 00:04:03,240
 output of the first call to the LLM, which essentially is going

65
00:04:03,240 --> 00:04:06,720
 to create a plan for the essay. And then the second one is going

66
00:04:06,720 --> 00:04:10,080
 to write the essay following the structure from the previous

67
00:04:10,400 --> 00:04:14,440
 output. So the essay that we're going to write now is going to be

68
00:04:14,440 --> 00:04:20,120
 based on this essay plan. So it's going to be like defining the

69
00:04:20,120 --> 00:04:23,080
 scope and then arguing the benefits and then examining the

70
00:04:23,080 --> 00:04:28,760
 challenges. So that's pretty much all it's going to do. So we're

71
00:04:28,760 --> 00:04:30,920
 going to wait a few seconds. I'm probably going to skip this.

72
00:04:40,400 --> 00:04:48,840
 Perfect. So now we can see that the first output was the plan

73
00:04:48,840 --> 00:04:52,560
 and the second output was the actual essay. So our chaining

74
00:04:52,560 --> 00:04:56,440
 works. And we can do this for all sorts of lists of prompts

75
00:04:56,440 --> 00:04:59,600
 for whatever workflow we're trying to build. All right. Now,

76
00:04:59,600 --> 00:05:02,600
 number three starts to get interesting because we start

77
00:05:02,600 --> 00:05:06,680
 routing at a LEM calls. So routing essentially means this.

78
00:05:06,680 --> 00:05:09,520
 If we go back to the building effective agents and we go to the

79
00:05:09,520 --> 00:05:10,960
 router pattern section.

80
00:05:10,960 --> 00:05:19,240
 Router here, we go here, we get augmented chaining, there

81
00:05:19,240 --> 00:05:23,640
 you go, routing. So here we have an LLM first. And what the LLM

82
00:05:23,640 --> 00:05:29,200
 is going to do is going to route the input to one of as many as

83
00:05:29,200 --> 00:05:34,240
 we want LLMs, not as many as we want, but like to one of X

84
00:05:34,240 --> 00:05:38,680
 LLMs. And one of those LLMs is going to take in the input. It's

85
00:05:38,680 --> 00:05:43,080
 going to provide us with an output as simple as that. So to do

86
00:05:43,080 --> 00:05:47,200
 that, all we got to do is we set up a little dictionary that's

87
00:05:47,200 --> 00:05:52,840
 going to contain a tag that indicates what is the selected

88
00:05:52,840 --> 00:06:00,040
 prompt for the LLM that has been routed. And in this case, I

89
00:06:00,040 --> 00:06:03,720
 have two simple tags, two simple classifications, right? We

90
00:06:03,720 --> 00:06:07,800
 have a coding prompt and a math prompt. So if the router

91
00:06:07,800 --> 00:06:12,240
 identifies that the input is related to coding, the router is

92
00:06:12,240 --> 00:06:16,680
 going to output something that can be parsed as coding. And

93
00:06:16,680 --> 00:06:19,840
 then we're going to, the prompt is going to be take this coding

94
00:06:19,840 --> 00:06:23,240
 problem and produce a solution invite. So essentially, if the

95
00:06:23,240 --> 00:06:26,040
 input is a coding problem or something related to producing

96
00:06:26,040 --> 00:06:32,240
 code, the the router is going to output coding. And if the

97
00:06:32,240 --> 00:06:35,120
 problems that are math, the router is going to output math.

98
00:06:35,120 --> 00:06:38,000
 That's pretty much all it does. Obviously, it could be a little

99
00:06:38,000 --> 00:06:41,880
 bit smarter input here, something like if none of these

100
00:06:41,880 --> 00:06:46,000
 topics are like, if the input is not about any of these topics,

101
00:06:46,000 --> 00:06:50,200
 we can produce an output like default, like none or something

102
00:06:50,200 --> 00:06:54,200
 like that, but we don't really need to do that. So now level

103
00:06:54,200 --> 00:06:58,240
 three, which is routing is going to take in some input in this

104
00:06:58,240 --> 00:07:03,200
 dictionary containing the coding and the math prompts. And now

105
00:07:03,200 --> 00:07:05,640
 we're going to write a little selector prompt, which is going

106
00:07:05,640 --> 00:07:08,480
 to say, analyze the input and classify it as one of the

107
00:07:08,480 --> 00:07:12,560
 following categories. Then we're going to list the router keys,

108
00:07:12,560 --> 00:07:17,680
 right, the keys from this dictionary. So coding and math.

109
00:07:17,680 --> 00:07:21,240
 And then we give an example just to make sure that the model is

110
00:07:21,240 --> 00:07:24,840
 going to get it right. Okay. So we show it like input, write a

111
00:07:24,840 --> 00:07:28,120
 Python function to read a file and then output coding, input,

112
00:07:28,120 --> 00:07:31,320
 salty equation, two x plus three equal 11. And then the output

113
00:07:31,320 --> 00:07:36,640
 is pretty simple, right? And then we start with the input given

114
00:07:36,640 --> 00:07:41,200
 by the user. Now what we do is we make a call to the other

115
00:07:41,200 --> 00:07:45,600
 lab, which hopefully will return either coding or math. And

116
00:07:45,600 --> 00:07:49,840
 then we print, we print that out so that we can make sure that

117
00:07:49,840 --> 00:07:54,040
 everything's working. And then we identify the selected prompt

118
00:07:54,040 --> 00:07:57,960
 from the dictionary based on the key that's going to come out of

119
00:07:57,960 --> 00:08:03,680
 this LLM call. And finally, we make the LLM call and return

120
00:08:03,680 --> 00:08:07,680
 that. So the output of the LLM call with the selected prompt

121
00:08:07,680 --> 00:08:11,680
 from this dictionary, which is going to be either the value for

122
00:08:11,680 --> 00:08:18,240
 this coding prompt or the math prompt. And the input given by

123
00:08:18,240 --> 00:08:21,160
 the user has the input that's going to be processed by this

124
00:08:21,160 --> 00:08:25,240
 prompt with this LLM call, which is the call to this function

125
00:08:25,240 --> 00:08:29,160
 that we wrote back here, called LLM call, which uses the

126
00:08:29,160 --> 00:08:33,920
 GPT five mini model to process the output process the input. So

127
00:08:33,920 --> 00:08:40,200
 when we do that, so when we do that, no, let me just go here,

128
00:08:40,200 --> 00:08:44,120
 running the following prompt. So we're going to run that. And

129
00:08:44,120 --> 00:08:46,800
 now we're going to use it. So I'm going to say write some code,

130
00:08:47,600 --> 00:08:51,760
 they can load a PDF and extract the headers of the document. And

131
00:08:51,760 --> 00:08:55,080
 then I give the dictionary that contains the possible routes.

132
00:08:55,080 --> 00:08:59,000
 Okay. And we're going to print that output. So now we're going

133
00:08:59,000 --> 00:08:59,880
 to send that out.

134
00:09:17,600 --> 00:09:32,640
 All right, perfect. So we're done running. So as you can see,

135
00:09:32,640 --> 00:09:36,480
 the output was coding. And then it ran the output for the

136
00:09:36,480 --> 00:09:41,840
 coding prompt. And it produced some very reliable output,

137
00:09:41,840 --> 00:09:44,840
 produced something that makes sense with the prompt. So we're

138
00:09:44,840 --> 00:09:47,880
 done. This is pretty good. Now, it's important to note that

139
00:09:47,880 --> 00:09:52,320
 these two examples for chaining and routing, I adapted them from

140
00:09:52,320 --> 00:09:56,720
 a really cool cool book from a cookbook from anthropic, which

141
00:09:56,720 --> 00:10:00,960
 you can check out on this article as well. Let me just

142
00:10:00,960 --> 00:10:05,560
 show you cookbook. There you go. So if you're going here, so

143
00:10:05,560 --> 00:10:08,480
 this is the cookbook. And I have it referenced in the notebook.

144
00:10:08,480 --> 00:10:10,800
 And I'm going to make the notebook available on GitHub. So

145
00:10:10,800 --> 00:10:14,080
 you you have access to it. And this example was from the basic

146
00:10:14,080 --> 00:10:18,200
 workflow notebook. However, they did this tailor to the cloud

147
00:10:18,200 --> 00:10:22,720
 API. And I did it tailored to the opening API. But it's pretty

148
00:10:22,720 --> 00:10:26,440
 similar with the difference that they did some XML parsing. And

149
00:10:26,440 --> 00:10:29,120
 I'm not doing that in the example we're seeing now. But

150
00:10:29,120 --> 00:10:32,200
 this is an awesome notebook. If you want to do stuff from scratch,

151
00:10:32,200 --> 00:10:37,240
 this is a great starting point. So going back, now we're going to

152
00:10:37,240 --> 00:10:41,360
 go to level four, which is when we combine LLMs with the

153
00:10:41,360 --> 00:10:44,720
 information of some available functions. And we put that

154
00:10:44,720 --> 00:10:47,760
 information inside of the prompt to the model to see if the

155
00:10:47,760 --> 00:10:52,480
 model is able to make calls to those functions. And the

156
00:10:52,480 --> 00:10:55,840
 inspiration for that was from a paper called two former, where

157
00:10:55,840 --> 00:10:59,040
 language models taught themselves how to use tools, a pretty

158
00:10:59,040 --> 00:11:04,240
 simple way. All they did was to provide outputs as text, which

159
00:11:04,240 --> 00:11:08,800
 were inside of the text, they had special strings that could be

160
00:11:08,800 --> 00:11:13,000
 parsed into function calls that we can run with Python code.

161
00:11:13,000 --> 00:11:16,960
 Okay, like you can see here, this is this thing in purple can be

162
00:11:16,960 --> 00:11:22,160
 run as a Python function, which calls this Q and API or Q and a

163
00:11:22,160 --> 00:11:27,840
 function. Okay, so inspired by this paper, we're going to do a

164
00:11:27,840 --> 00:11:31,720
 very simple example. So we're going to load up some imports.

165
00:11:31,720 --> 00:11:34,960
 And what we're going to do here is essentially, we start with

166
00:11:34,960 --> 00:11:39,680
 something very silly simple function, which essentially is

167
00:11:39,680 --> 00:11:44,520
 going to set us up in the in a base directory. And then if it's

168
00:11:44,520 --> 00:11:49,040
 not, it's going to handle some errors. The most important

169
00:11:49,040 --> 00:11:51,440
 thing is that we're going to write two functions, one to read

170
00:11:51,440 --> 00:11:55,240
 files and one to write files. So we're going to read a file. So

171
00:11:55,240 --> 00:11:58,520
 this function is going to take in a file path. And it's going to

172
00:11:58,520 --> 00:12:02,680
 set the base directory and then read the file on side of that

173
00:12:02,680 --> 00:12:07,040
 path. Same thing for the right file function, it's going to set

174
00:12:07,040 --> 00:12:11,080
 the base directory and then it's going to write a file in the

175
00:12:11,080 --> 00:12:16,320
 specified file path. Okay, pretty simple, pretty easy. So now,

176
00:12:16,320 --> 00:12:20,280
 what we're going to do is the level four is going to be about

177
00:12:20,280 --> 00:12:25,200
 merging the LLM with the functions inside of the prompt. So

178
00:12:25,200 --> 00:12:28,040
 for that, all we're going to do is we're going to write a

179
00:12:28,040 --> 00:12:35,080
 little piece of code that gets the function as a string. So I use

180
00:12:35,080 --> 00:12:38,600
 the inspect module, which I didn't know existed, honestly, up

181
00:12:38,600 --> 00:12:41,920
 to today. So that was pretty cool. Because in the previous

182
00:12:41,920 --> 00:12:45,360
 example that I did on my latest video, my lesson, my last video

183
00:12:45,360 --> 00:12:50,640
 on this topic, I actually put the functions as strings inside

184
00:12:50,640 --> 00:12:53,600
 of the prompt manually. So it's nice to know that I can do

185
00:12:53,600 --> 00:12:58,320
 that programmatically. Now, I have a full prompt that contains

186
00:12:58,320 --> 00:13:01,880
 the information about the functions to write files and read

187
00:13:01,880 --> 00:13:05,040
 files. Okay. And what we're going to do with that is we're

188
00:13:05,040 --> 00:13:10,960
 going to send input to the OpenAI Responses API with the

189
00:13:10,960 --> 00:13:14,720
 GPT five mini mod. And we're going to say you're a helpful

190
00:13:14,720 --> 00:13:18,480
 assistant that can write and read files. This used to be the

191
00:13:18,480 --> 00:13:22,520
 system message from the previous version of their API. But now

192
00:13:22,520 --> 00:13:26,440
 they change it to instructions. It's the same thing. So now this

193
00:13:26,440 --> 00:13:29,600
 model has the information about the two functions available

194
00:13:29,600 --> 00:13:35,200
 plus has instructions about using these tools. So we're going

195
00:13:35,200 --> 00:13:37,800
 to see if this model is able to produce an output that we can

196
00:13:37,800 --> 00:13:42,280
 transform into an execution of the function indicated. So let's

197
00:13:42,280 --> 00:13:48,280
 see if that's possible. So let's see. This call level for a

198
00:13:48,280 --> 00:13:52,160
 Lamb function in prompt takes an input prompt like this, write a

199
00:13:52,160 --> 00:13:55,800
 file called test the content hello world. And then I give it a

200
00:13:55,800 --> 00:14:00,000
 list of the tools available. So write file and read file. Okay.

201
00:14:00,000 --> 00:14:07,080
 And what we're going to do now. Yeah, we're going to now we're

202
00:14:07,080 --> 00:14:13,280
 going to run this. And we're going to see the output of the

203
00:14:13,280 --> 00:14:16,280
 function call. We're going to see the output of this function.

204
00:14:17,520 --> 00:14:20,280
 So as you can see, the output of this function is exactly what

205
00:14:20,280 --> 00:14:26,920
 we need, which is a string that exactly reads as the calling of

206
00:14:26,920 --> 00:14:30,960
 the right function for the task. So what we're going to do is

207
00:14:30,960 --> 00:14:34,200
 we're going to use Python's built in exact module, which you can

208
00:14:34,200 --> 00:14:37,040
 check out in the Python documentation, which essentially

209
00:14:37,040 --> 00:14:42,560
 supports dynamic execution of Python code. Okay, so supports

210
00:14:42,560 --> 00:14:46,200
 dynamic execution Python code. That's what it does. So we're

211
00:14:46,200 --> 00:14:52,080
 going to use it to execute this string that indicates that we

212
00:14:52,080 --> 00:14:56,880
 have to write the file. Okay, so when we do that, what happens

213
00:14:56,880 --> 00:15:03,440
 is that we execute the action. So if we do a cat on the output of

214
00:15:03,440 --> 00:15:07,200
 test.txt to see if it was created, you see that it was

215
00:15:07,200 --> 00:15:11,520
 created. So it's perfect. So what I want you to start seeing

216
00:15:11,520 --> 00:15:16,400
 is that we're evolving from calling LLM APIs to trying to

217
00:15:16,400 --> 00:15:20,440
 give LLM the ability to perform actions. But we are in the

218
00:15:20,440 --> 00:15:24,000
 initial stages of that. Let's see how we can evolve even

219
00:15:24,000 --> 00:15:28,080
 further. Now we're going to look at something called structured

220
00:15:28,080 --> 00:15:32,040
 outputs. Now structure outputs, it's a very interesting thing.

221
00:15:32,040 --> 00:15:36,760
 What it does is essentially give these LLM the ability to take

222
00:15:36,800 --> 00:15:41,600
 unstructured data and produce structured data, so structured

223
00:15:41,600 --> 00:15:46,800
 outputs. That's what it does. And there's no official paper on

224
00:15:46,800 --> 00:15:49,520
 this topic, which I found kind of weird, but I think one of the

225
00:15:49,520 --> 00:15:53,080
 best resources that you can see that are open source on the

226
00:15:53,080 --> 00:15:59,080
 topic are either this JSON form or GitHub repo from hugging

227
00:15:59,080 --> 00:16:02,680
 face, where they show a bulletproof way to generate structured

228
00:16:02,680 --> 00:16:06,880
 JSON from language models. It's super cool, and you can see a

229
00:16:06,880 --> 00:16:11,360
 little bit about it. But the major source for knowledge on this

230
00:16:11,360 --> 00:16:14,120
 topic has been the OpenAI Docs on structure outputs when they

231
00:16:14,120 --> 00:16:19,800
 released it in 2024. And essentially what you see is that

232
00:16:19,800 --> 00:16:26,600
 you can produce structured output. So an object given something

233
00:16:26,600 --> 00:16:30,840
 called a JSON schema. And what the JSON schema is is

234
00:16:30,840 --> 00:16:35,960
 essentially something that defines, okay, what is the, what is

235
00:16:35,960 --> 00:16:40,320
 the structure of my object? Okay. So essentially, what that

236
00:16:40,320 --> 00:16:44,640
 means is that we can indicate to the model, look, I want to

237
00:16:44,640 --> 00:16:47,360
 produce an output that has this structure, and the model is

238
00:16:47,360 --> 00:16:50,160
 going to produce an output that adheres to the structure that I

239
00:16:50,160 --> 00:16:55,640
 want. So for example, I'm going to transform the previous

240
00:16:55,640 --> 00:16:59,840
 example that we're doing into a structured output problem. So I'm

241
00:16:59,840 --> 00:17:03,720
 going to create a class called right file operation. And I'm

242
00:17:03,720 --> 00:17:08,280
 going to be using a module, a very cool package in Python

243
00:17:08,280 --> 00:17:14,840
 called by dentic. So what by dentic is by dentic. So by dentic

244
00:17:14,840 --> 00:17:18,280
 is essentially a data validation library in Python that works

245
00:17:18,280 --> 00:17:21,440
 amazingly well with LLM's. It's probably one of the most

246
00:17:21,440 --> 00:17:25,600
 important packages out there on the LLM era that we're living

247
00:17:25,600 --> 00:17:29,040
 right now. So what we're going to do is we're going to create a

248
00:17:29,040 --> 00:17:31,880
 little object called right file operation. It's going to have

249
00:17:31,880 --> 00:17:36,080
 two attributes, the file path, which contains the file where

250
00:17:36,080 --> 00:17:40,480
 the file should be saved, and the contents of that file. So this

251
00:17:40,480 --> 00:17:45,320
 is mimicking the operation of writing a file with the right

252
00:17:45,320 --> 00:17:48,120
 file function. But instead of calling that function, we're

253
00:17:48,120 --> 00:17:54,080
 producing the arguments to call that function. Hopefully, you

254
00:17:54,080 --> 00:17:57,720
 see where we're going with this. And we're going to do the

255
00:17:57,720 --> 00:18:01,000
 same with the reap file function. So reap file operation in the

256
00:18:01,000 --> 00:18:05,040
 file path. Now, we're going to write a prompt like write a file

257
00:18:05,040 --> 00:18:10,200
 called test2.txt with the content hello world again. And we're

258
00:18:10,200 --> 00:18:14,880
 going to make a call to the open AI responses API. But with the

259
00:18:14,880 --> 00:18:20,480
 little added feature, we're going to set the best format for

260
00:18:20,480 --> 00:18:24,560
 the output of this model to adhere to the right file

261
00:18:24,560 --> 00:18:28,320
 operation object. So that means that this output is going to

262
00:18:28,320 --> 00:18:33,080
 contain these attributes file path and content. Hopefully, being

263
00:18:33,080 --> 00:18:37,520
 tailored to the prompt that we're writing right here. So the

264
00:18:37,520 --> 00:18:42,160
 file path hopefully is going to be test2.txt. And the contents

265
00:18:42,160 --> 00:18:46,400
 are going to be hello world again. So now we're going to do

266
00:18:46,400 --> 00:18:49,000
 that. And then we're going to see what that output looks like.

267
00:18:54,600 --> 00:18:59,080
 Perfect. So as you can see, we were able to obtain exactly

268
00:18:59,080 --> 00:19:04,520
 what we wanted. So we obtained it programmatically, because we

269
00:19:04,520 --> 00:19:07,920
 created something that's a structured object represented by

270
00:19:07,920 --> 00:19:12,760
 response dot output parts, which if we look at it is actually the

271
00:19:12,760 --> 00:19:17,320
 object that we were hoping for. So if I create this here and I

272
00:19:17,320 --> 00:19:19,960
 output, you can see that it says the object, it contains the

273
00:19:19,960 --> 00:19:26,240
 things that we were looking for. So now we can write level five.

274
00:19:26,240 --> 00:19:31,080
 And level five is going to be about leveraging this to execute

275
00:19:31,080 --> 00:19:35,360
 an action, similarly to what we did before with the functions

276
00:19:35,360 --> 00:19:38,800
 inside of the prompt. But this time we're leveraging structured

277
00:19:38,800 --> 00:19:43,480
 outputs instead. So we're going to write the response to the

278
00:19:43,480 --> 00:19:48,120
 LMBPI. And we're going to write the format to be right file

279
00:19:48,120 --> 00:19:53,400
 operation. And then we're going to get the arguments back

280
00:19:53,400 --> 00:19:58,640
 programmatically. And then we're going to call the function

281
00:19:58,640 --> 00:20:04,120
 right file super simple, super easy. So now we're going to call

282
00:20:04,120 --> 00:20:07,680
 this and see what happens. Hopefully what's going to happen

283
00:20:07,680 --> 00:20:14,320
 is that the model is going to extract this as file path. And

284
00:20:14,320 --> 00:20:18,400
 this has the content of the file. And then it's going to

285
00:20:18,400 --> 00:20:22,400
 execute the function correctly. Now, obviously, if I was doing

286
00:20:22,400 --> 00:20:24,840
 something more serious, I would have to put a bunch of error

287
00:20:24,840 --> 00:20:27,920
 handling here and a bunch of other stuff. But for now, I think

288
00:20:27,920 --> 00:20:31,920
 that this is more than enough. So we're going to call this

289
00:20:31,920 --> 00:20:40,400
 it seems like it worked. So we're going to test that out. Perfect

290
00:20:40,520 --> 00:20:45,800
 it works. So now we're going to go even further. So we're going

291
00:20:45,800 --> 00:20:51,200
 to go to level six and level six is function calling. Now, it's

292
00:20:51,200 --> 00:20:54,040
 important to note that I'm talking about structured outputs

293
00:20:54,040 --> 00:20:57,440
 before I'm talking about function calling, which is a choice I

294
00:20:57,440 --> 00:21:02,920
 made. But chronologically, function calling came first, it

295
00:21:02,920 --> 00:21:06,680
 was released in June of 2023 in the open API. If we go to the

296
00:21:06,680 --> 00:21:13,600
 release post, we can see here, June, June 2023, the function

297
00:21:13,600 --> 00:21:18,000
 calling API was released by OpenAI. And if we go to the

298
00:21:18,000 --> 00:21:22,000
 release post by structure outputs, that was in August of

299
00:21:22,000 --> 00:21:27,960
 2024. However, conceptually structure outputs underlies

300
00:21:27,960 --> 00:21:31,320
 what makes function calling possible, because it's the

301
00:21:31,320 --> 00:21:36,000
 ability to produce outputs that adhere to a certain JSON

302
00:21:36,000 --> 00:21:40,520
 schema structure. So what is the function calling? We already

303
00:21:40,520 --> 00:21:44,840
 saw that in practice, we saw that we can transform the outputs

304
00:21:44,840 --> 00:21:49,200
 of an LLM into calls to functions. So function calling is

305
00:21:49,200 --> 00:21:53,520
 just the integration of the capability directly into the

306
00:21:53,520 --> 00:21:57,960
 LLM API, in this case, the opening API. And we're going to

307
00:21:57,960 --> 00:22:02,320
 do that by leveraging what the open API allows us to do. And

308
00:22:02,360 --> 00:22:05,760
 we're going to make cost of functions, we're going to allow

309
00:22:05,760 --> 00:22:09,440
 LLMs to take actions autonomously with this capability

310
00:22:09,440 --> 00:22:15,080
 similarly to what we did before. So to do that, we're going to

311
00:22:15,080 --> 00:22:19,600
 set up a better way to inform the LLM about the available tools

312
00:22:19,600 --> 00:22:25,400
 or functions. And then we're going to see if the LLM is able

313
00:22:25,400 --> 00:22:29,360
 to call them. So to do that, we got the final list of callable

314
00:22:29,360 --> 00:22:32,800
 tools for the model. And that list is going to be a list of

315
00:22:32,800 --> 00:22:37,160
 dictionaries that have a type, in this case, function, and then

316
00:22:37,160 --> 00:22:40,240
 we say write file, we give a description, and we give the

317
00:22:40,240 --> 00:22:44,400
 parameters that go with a function. So this is similar to

318
00:22:44,400 --> 00:22:47,760
 put the to putting the functions inside of the prompt, but we do

319
00:22:47,760 --> 00:22:52,560
 it as a JSON object to be a little bit more structurally

320
00:22:52,560 --> 00:22:56,800
 sound. So we're doing that for both functions, we're defining

321
00:22:56,800 --> 00:23:00,440
 the required parameters, the contents of each of the parameters

322
00:23:00,440 --> 00:23:03,960
 or if things good. So once we've done that, what we're going to

323
00:23:03,960 --> 00:23:07,640
 do next is we're going to write down, I'm going to rewrite the

324
00:23:07,640 --> 00:23:13,600
 read and write file functions just to be thorough. And what we're

325
00:23:13,600 --> 00:23:16,160
 going to do now is we're going to set up a list of inputs

326
00:23:16,160 --> 00:23:19,120
 through the model, which is just going to have one input. And

327
00:23:19,120 --> 00:23:21,920
 the inputs can to be create a file called test function

328
00:23:21,920 --> 00:23:26,840
 calling.txt with the content level six function calling. That's

329
00:23:26,840 --> 00:23:31,240
 it. So now we're going to make a call to the open API. We're going

330
00:23:31,240 --> 00:23:35,280
 to set the tools parameter to the list that we created called

331
00:23:35,280 --> 00:23:39,040
 tools. And we're going to set two choice to auto, because that

332
00:23:39,040 --> 00:23:42,600
 sets the choice of a to call to be automatically selected by the

333
00:23:42,600 --> 00:23:46,600
 model, in this case, by GPT five mini. And then we're going to

334
00:23:46,600 --> 00:23:51,320
 give the input as this little list of inputs, which could be

335
00:23:51,320 --> 00:23:55,080
 just the just the prompt itself. It doesn't have to be this list

336
00:23:55,080 --> 00:23:59,160
 of dictionaries. Okay, however, I think the responses API is

337
00:23:59,160 --> 00:24:02,960
 kind of backwards compatible with the previous version. And

338
00:24:02,960 --> 00:24:06,760
 that's why this thing still works. So now we're going to do

339
00:24:06,760 --> 00:24:09,960
 that. And then what we're going to do is we're going to save

340
00:24:09,960 --> 00:24:14,040
 the functional call outputs for subsequent requests. So stick

341
00:24:14,040 --> 00:24:18,400
 with me on this. So here's the thing, when we get the output

342
00:24:18,720 --> 00:24:25,280
 from the model, we're going to inspect to see if any of the

343
00:24:25,280 --> 00:24:28,480
 items inside of the output, which is going to be a list of

344
00:24:28,480 --> 00:24:32,520
 objects, any of them should have a type of function call, which

345
00:24:32,520 --> 00:24:36,960
 indicates that a call to a function was made. And then we're

346
00:24:36,960 --> 00:24:40,800
 going to inspect the names of those function calls. And if they

347
00:24:40,800 --> 00:24:45,400
 match the functions that we actually have, we are going to

348
00:24:45,400 --> 00:24:49,560
 take care of the part of making of calling those functions. So

349
00:24:49,560 --> 00:24:52,760
 we're going to say, okay, let's obtain the arguments that the

350
00:24:52,760 --> 00:24:58,280
 model determine should be used for the function call. And then

351
00:24:58,280 --> 00:25:02,000
 here, I'm doing it kind of like semi manually, because I already

352
00:25:02,000 --> 00:25:05,600
 know for the right file, what are the arguments? So I'm taking

353
00:25:05,600 --> 00:25:10,280
 them here like this. And then I'm calling I'm making myself the

354
00:25:10,280 --> 00:25:15,880
 call to the right file function. Now this is very similar to what

355
00:25:15,880 --> 00:25:19,600
 we did before, but we're leveraging the API to be more

356
00:25:19,600 --> 00:25:24,720
 deterministic about these executions of these functions. And

357
00:25:24,720 --> 00:25:30,240
 they were appending the outputs of these executions, so that the

358
00:25:30,240 --> 00:25:37,800
 model can compile the initial input and the outputs of the

359
00:25:37,800 --> 00:25:41,160
 functions to produce a comprehensive response to the

360
00:25:41,160 --> 00:25:46,040
 user. So we're doing a similar thing to read file. And then

361
00:25:46,040 --> 00:25:51,800
 finally, we make a second call to the LLM containing

362
00:25:51,800 --> 00:25:55,680
 everything that happened, including the initial prompt in

363
00:25:55,680 --> 00:26:01,880
 the function calls and their outputs. So now we can inspect

364
00:26:01,880 --> 00:26:05,280
 what the final output looks like. So I'm going to run this.

365
00:26:07,800 --> 00:26:15,920
 And there you go. It seems like the file was created. And we

366
00:26:15,920 --> 00:26:23,160
 can test that and perfect. It was created. Awesome. So there you

367
00:26:23,160 --> 00:26:27,000
 go. Now it starts to get interesting, because now we've

368
00:26:27,000 --> 00:26:32,600
 learned about basic LLM calls, chaining calls, routing calls,

369
00:26:33,080 --> 00:26:38,080
 putting functions inside prompts, using structured outputs to

370
00:26:38,080 --> 00:26:42,440
 transform and structure data via LLM's into structured objects.

371
00:26:42,440 --> 00:26:48,640
 And we've learned about function calling with the open API. Now,

372
00:26:48,640 --> 00:26:51,200
 let's build a agent. Let's build something that can

373
00:26:51,200 --> 00:26:55,520
 autonomously, autonomously make decisions and execute actions

374
00:26:55,520 --> 00:27:01,000
 and loop over the usage of these tools and execution of

375
00:27:01,000 --> 00:27:06,880
 actions to perform complex tasks. So the inspiration for this

376
00:27:06,880 --> 00:27:09,680
 next demonstration comes from a really awesome paper called

377
00:27:09,680 --> 00:27:14,520
 React. And this paper, which I have it listed here in the

378
00:27:14,520 --> 00:27:17,000
 notebook, which is called synergizing reasoning and acting

379
00:27:17,000 --> 00:27:20,320
 language models. What this paper does is they show that there's

380
00:27:20,320 --> 00:27:23,600
 a way that you can prompt the model to incentivize the

381
00:27:23,600 --> 00:27:29,360
 interleaving of thoughts, like plans for what to do, and

382
00:27:29,600 --> 00:27:34,800
 actions, which mean essentially executing some programs and

383
00:27:34,800 --> 00:27:38,960
 function, which will lead to an observation that the model is

384
00:27:38,960 --> 00:27:43,200
 going to use to be able to get further and further in solving

385
00:27:43,200 --> 00:27:48,360
 the task. So this paper is really cool. And what you can do

386
00:27:48,360 --> 00:27:50,840
 with this is what we're going to try to do is we're going to

387
00:27:50,840 --> 00:27:55,000
 try to build from scratch only only using the LLM API in Python

388
00:27:55,000 --> 00:27:59,280
 code. This entire react agent loop, which is a really good way

389
00:27:59,280 --> 00:28:04,960
 to understand how modern agents work. So I'm going to, again,

390
00:28:04,960 --> 00:28:08,840
 write the read file, write file functions back into the cell

391
00:28:08,840 --> 00:28:13,560
 here just to be thorough. Then I'm going to write a little

392
00:28:13,560 --> 00:28:18,080
 mapping object here, which is essentially just dictionary

393
00:28:18,080 --> 00:28:22,160
 that maps the names read file and write file to the correct

394
00:28:22,160 --> 00:28:26,440
 corresponding functions. Okay. Now we're going to have a

395
00:28:26,440 --> 00:28:31,240
 list of tools, which is the same as we did before. Okay, it's

396
00:28:31,240 --> 00:28:36,640
 pretty similar to the thing that we did before. So it's the

397
00:28:36,640 --> 00:28:40,800
 write file read file to descriptions as dictionaries. Okay,

398
00:28:40,800 --> 00:28:46,320
 so these are the JSON schemas of those functions. Now, for the

399
00:28:46,320 --> 00:28:49,480
 instructions for this model, we're going to have a few things

400
00:28:49,480 --> 00:28:53,920
 that we need to address. The first one is this, your careful

401
00:28:53,920 --> 00:28:57,240
 system that can use tools to read and write files. Okay, great.

402
00:28:57,240 --> 00:29:01,040
 If a task involves files, call the appropriate tool with

403
00:29:01,040 --> 00:29:04,520
 precise arguments. After two calls, summarize results for the

404
00:29:04,520 --> 00:29:09,400
 user, only write files when explicitly asked or when

405
00:29:09,400 --> 00:29:11,880
 necessary to complete the task. This is just to increase the

406
00:29:11,880 --> 00:29:17,120
 chance of a good two calls. So the model being precise about

407
00:29:17,120 --> 00:29:21,120
 calling the right tools. And then if something is ambiguous,

408
00:29:21,200 --> 00:29:24,600
 ask a concise clarifying question. When you're done, respond

409
00:29:24,600 --> 00:29:28,040
 with final answer. And I'm doing this here just because we

410
00:29:28,040 --> 00:29:32,920
 want to be able to parse some indication that a loop of

411
00:29:32,920 --> 00:29:36,040
 actions should end. And we can actually provide an answer to

412
00:29:36,040 --> 00:29:44,080
 the user. So now I wrote this with AI and just to safely load

413
00:29:45,280 --> 00:29:51,560
 the JSON schemas of the tools that were going to be used. And

414
00:29:51,560 --> 00:29:55,840
 then we're going to have something to if a loop goes for too

415
00:29:55,840 --> 00:29:58,400
 long, we want to have something like this that summarizes

416
00:29:58,400 --> 00:30:03,360
 what happened to the model. And without overloading the context

417
00:30:03,360 --> 00:30:07,240
 window of the model, so all the text the model can read. And

418
00:30:07,240 --> 00:30:10,800
 now we're going to finally write level seven, the react agent

419
00:30:10,800 --> 00:30:13,720
 loop. And what we're going to have for this function is a

420
00:30:13,720 --> 00:30:18,200
 task prompt, which describes what the problem is. And then we're

421
00:30:18,200 --> 00:30:21,160
 going to set the maximum number of turns that the model can

422
00:30:21,160 --> 00:30:25,320
 actually loop and use tools to solve the task. Okay, I set the

423
00:30:25,320 --> 00:30:28,480
 default to eight, but you can do it for like three. And that should

424
00:30:28,480 --> 00:30:33,960
 be fine. Now we're going to start with that input. And here's

425
00:30:33,960 --> 00:30:36,760
 what we're going to do. We're going to loop over the maximum

426
00:30:36,760 --> 00:30:40,920
 amount of turns that we can do. And each turn involves making a

427
00:30:40,920 --> 00:30:46,080
 call to the LLM API, reading and executing the functions that

428
00:30:46,080 --> 00:30:52,160
 are called. And then seeing if we've reached the final answer, if

429
00:30:52,160 --> 00:30:54,720
 not, we're going to go yet. So for that, we're going to start

430
00:30:54,720 --> 00:30:57,640
 with calling the model using the similar structure that we did

431
00:30:57,640 --> 00:31:01,120
 before. And now, so what we're going to be doing here is we're

432
00:31:01,120 --> 00:31:06,600
 going to be taking all the function calls that we identifying

433
00:31:06,600 --> 00:31:10,320
 the model's response output. And we're going to execute those

434
00:31:10,320 --> 00:31:14,640
 function calls, just like we did in the previous example. So

435
00:31:14,640 --> 00:31:17,560
 we're going to identify them by the name. And then we're going to

436
00:31:17,560 --> 00:31:22,880
 use the pi tools mapping dictionary that we built for the

437
00:31:22,880 --> 00:31:26,520
 write file and read file. And then we're going to use that to get

438
00:31:26,520 --> 00:31:30,880
 the actual function to be able to execute that function. So you

439
00:31:30,880 --> 00:31:33,360
 execute the function, we write a little bit of some try

440
00:31:33,360 --> 00:31:37,760
 accept statements to make sure that we can handle some error

441
00:31:37,800 --> 00:31:41,960
 messages. And then we append the output of the execution of the

442
00:31:41,960 --> 00:31:45,560
 functions to the input list that the model is going to be able to

443
00:31:45,560 --> 00:31:49,360
 see at the end to be able to compile a proper response to the

444
00:31:49,360 --> 00:31:56,160
 user. And what we do lastly is if and when the model produces

445
00:31:56,160 --> 00:32:00,920
 the final answer text inside of the output, that means that we're

446
00:32:00,920 --> 00:32:03,320
 done, we don't have to loop anymore, and we can provide an

447
00:32:03,320 --> 00:32:07,400
 answer to the user. So we parse that from the output using the

448
00:32:07,400 --> 00:32:13,000
 rejects module. And then we return, and if we don't for some

449
00:32:13,000 --> 00:32:17,840
 reason get to get to an actual output from the agent after the

450
00:32:17,840 --> 00:32:22,560
 all of the terms that we set with the max_turns parameter, we

451
00:32:22,560 --> 00:32:29,000
 just stop because we reach the maximum. All right. So now, we're

452
00:32:29,000 --> 00:32:32,360
 going to set up a complex task that involves two actions,

453
00:32:32,360 --> 00:32:36,120
 right, reading a file and then writing a summary of it to another

454
00:32:36,120 --> 00:32:40,840
 file. And we're going to test it with our react agent loop. And

455
00:32:40,840 --> 00:32:44,760
 we're going to see if it works. Perfect. Seems like it works. And

456
00:32:44,760 --> 00:32:48,840
 we can test that by going to the summary file. We see that we

457
00:32:48,840 --> 00:32:51,720
 got the summary file. And we see that it's talking about

458
00:32:51,720 --> 00:32:55,080
 embeddings. If we go to the sample input file, we see that the

459
00:32:55,080 --> 00:33:00,280
 input was about embeddings. So it seems like it works. So this

460
00:33:00,280 --> 00:33:02,760
 is great. What we're going to do now is we're going to go to the

461
00:33:02,760 --> 00:33:07,240
 final level, let's say, which is the actual Agentec workflow. And

462
00:33:07,240 --> 00:33:10,360
 this is going to be an Agentec workflow that uses agents. But

463
00:33:10,360 --> 00:33:15,000
 instead of the end goal being the agent, the agent is just a step

464
00:33:15,000 --> 00:33:20,680
 in a more complex system that merges the idea of simpler steps

465
00:33:20,680 --> 00:33:26,920
 using just a simple LML call with possible agents, depending on

466
00:33:26,920 --> 00:33:31,560
 the routing mechanics of the previous input. What I mean by that

467
00:33:31,560 --> 00:33:34,440
 is we're going to take some input. And then we're going to use a

468
00:33:34,440 --> 00:33:38,520
 router LML call like we did in level three. Remember, we did first

469
00:33:38,520 --> 00:33:43,160
 test it for a LML call. And then we did a chaining of LML calls.

470
00:33:43,160 --> 00:33:48,360
 And the third example was the routing procedure, where it takes an input and

471
00:33:48,360 --> 00:33:52,760
 then it can route to one LML call or another. We're going to do that

472
00:33:52,760 --> 00:33:55,400
 same thing here. But this time, since we've learned about

473
00:33:55,400 --> 00:33:58,280
 structured outputs, we're going to be using structured outputs to do the

474
00:33:58,280 --> 00:34:01,880
 routing mechanics. And what we're going to do next is we're going to

475
00:34:01,880 --> 00:34:05,080
 route to either a jokes agent, which is going to be some agent that can

476
00:34:05,080 --> 00:34:10,840
 write to files and creates jokes or to a web search agent, which can

477
00:34:10,840 --> 00:34:15,560
 search the web and also write to files. Then the output is going to be produced

478
00:34:15,560 --> 00:34:18,920
 by either of those agents, depending on the input.

479
00:34:18,920 --> 00:34:22,680
 That's what we're going to do. So to start things off, we're going to set up

480
00:34:22,680 --> 00:34:26,840
 the routing mechanics. So to do that, we're going to set up a

481
00:34:26,840 --> 00:34:29,960
 class called router output. And this class is going to have one

482
00:34:29,960 --> 00:34:34,920
 attribute called category, which is going to be either the

483
00:34:34,920 --> 00:34:38,760
 string joke or the web search. So it's a simple classification

484
00:34:38,760 --> 00:34:42,760
 output. And then we're going to describe category of the input

485
00:34:42,760 --> 00:34:46,360
 joke or web search. And then finally, we're going to

486
00:34:46,360 --> 00:34:51,080
 make a test call to the LML to the OpenAI Responses API,

487
00:34:51,080 --> 00:34:55,000
 setting the text format to the router output to see if this thing works.

488
00:34:55,000 --> 00:34:58,760
 So I'm going to test that out right now. Perfect. It seems like it works.

489
00:34:58,760 --> 00:35:04,360
 It was able to identify that the input was about creating jokes.

490
00:35:04,360 --> 00:35:08,120
 Pretty simple problem. And now what we're going to do is we're going to set up

491
00:35:08,120 --> 00:35:12,040
 the tools for these agents. So for the Joker agent, it's just a simple

492
00:35:12,040 --> 00:35:16,280
 write file tool. And for the web search agent is the

493
00:35:16,280 --> 00:35:20,360
 write file tool and the ability to search the web, which in the OpenAI

494
00:35:20,360 --> 00:35:24,760
 Responses API, it already has a built-in tool for a web search, which we're

495
00:35:24,760 --> 00:35:29,160
 going to use. So that's what we have on the Joker

496
00:35:29,160 --> 00:35:32,360
 agent tools, pretty similar to what we did before. But this time is just for the

497
00:35:32,360 --> 00:35:37,000
 write file and web search, we have the write file tool.

498
00:35:37,000 --> 00:35:41,000
 And we have this, which is the statement that indicates the

499
00:35:41,000 --> 00:35:45,560
 OpenAI Responses API that the tool to use is the built-in

500
00:35:45,560 --> 00:35:50,600
 web search tool. Then I, this is just because we're doing

501
00:35:50,600 --> 00:35:54,680
 this from scratch. I did a little dictionary that

502
00:35:54,680 --> 00:36:01,080
 if the routing call is joke, we're going to route it to the Joker agent with

503
00:36:01,080 --> 00:36:05,000
 these instructions and these tools. And if it's web search, we're going to route

504
00:36:05,000 --> 00:36:08,200
 it to the web search agent with these instructions

505
00:36:08,200 --> 00:36:16,040
 and these tools. Pretty simple, right? So now we're going to run that.

506
00:36:16,040 --> 00:36:19,000
 All right. So after that, what we're going to do is we're going to set up the

507
00:36:19,000 --> 00:36:23,080
 this tool map variable, which is just a dictionary that maps the write file

508
00:36:23,080 --> 00:36:27,000
 to the function. So we run that. And now what we're going to do is we're going to

509
00:36:27,000 --> 00:36:31,400
 define a react agent loop similar to the one that we did before,

510
00:36:31,400 --> 00:36:35,160
 but with a catch. This is going to be a more modular

511
00:36:35,160 --> 00:36:39,400
 function that allows us to create specialized agents.

512
00:36:39,400 --> 00:36:43,560
 So it will take in the input. It will take in

513
00:36:43,560 --> 00:36:47,480
 the agent dictionary, which is going to be either this

514
00:36:47,480 --> 00:36:52,840
 or this, which essentially takes three keys, the name, the instructions and the

515
00:36:52,840 --> 00:36:56,360
 tools and the max turns, just like we did before.

516
00:36:56,360 --> 00:37:00,600
 And this is going to be very similar to before, but with the addition

517
00:37:00,600 --> 00:37:05,080
 that now we can actually make specialized agents based on the

518
00:37:05,080 --> 00:37:08,920
 custom set of instructions and a list of tools,

519
00:37:08,920 --> 00:37:11,960
 similar to what different frameworks do out there,

520
00:37:11,960 --> 00:37:15,800
 where you can create specialized agents with very simple input.

521
00:37:15,800 --> 00:37:19,640
 So we're going to set up our input list. We're going to set up the agent tools

522
00:37:19,640 --> 00:37:23,320
 by extracting it from the agent dictionary.

523
00:37:23,320 --> 00:37:26,440
 And then we're going to set up the loop similar to what we did before.

524
00:37:26,440 --> 00:37:30,440
 This is going to loop is going to make a call to the open API

525
00:37:30,440 --> 00:37:35,560
 with the instructions for the agent that will be

526
00:37:35,560 --> 00:37:39,640
 used, selected by the router call. And then we're going to

527
00:37:39,640 --> 00:37:43,400
 put that into the input list so that this

528
00:37:43,400 --> 00:37:47,000
 so that information will be stored in the

529
00:37:47,000 --> 00:37:51,560
 log of the agent. We're going to execute the function calls.

530
00:37:51,560 --> 00:37:57,080
 Remember folks that if the agent uses the web search tool,

531
00:37:57,080 --> 00:38:02,120
 this function call is this is not necessary because the web search

532
00:38:02,120 --> 00:38:05,960
 is executed by the opening API by default.

533
00:38:05,960 --> 00:38:10,200
 So this is just for functions that are defined outside of the scope of the

534
00:38:10,200 --> 00:38:14,440
 building tools. So then we're going to extract.

535
00:38:14,440 --> 00:38:18,280
 We're going to map it exactly similar to what we did before.

536
00:38:18,280 --> 00:38:23,000
 And the reason why I'm rewriting this is because I want to make each of these

537
00:38:23,000 --> 00:38:27,240
 levels kind of like self-contained. Then we're appending the outputs of the

538
00:38:27,240 --> 00:38:29,720
 function call execution of the function calls.

539
00:38:29,720 --> 00:38:33,000
 And we're doing similar to what we did before.

540
00:38:33,000 --> 00:38:37,240
 We're scraping the final answer. We're scraping the final answer with the rejects

541
00:38:37,240 --> 00:38:40,760
 module and then appending everything and

542
00:38:40,760 --> 00:38:45,080
 returning stopped if the maximum number of turns is

543
00:38:45,080 --> 00:38:50,600
 reached without a conclusion. Okay, perfect. So this looks good.

544
00:38:50,600 --> 00:38:55,400
 And now we can run this and we can finally write

545
00:38:55,400 --> 00:38:58,360
 the function that represents level 8 which is the

546
00:38:58,360 --> 00:39:01,960
 agentic workflow using this agent as a step. So

547
00:39:01,960 --> 00:39:05,640
 remember what we're building is a simple agentic workflow that takes

548
00:39:05,640 --> 00:39:09,320
 first a router which is going to use an element to route

549
00:39:09,320 --> 00:39:13,720
 the call to the input to either the jokes agent or the web search agent.

550
00:39:13,720 --> 00:39:16,280
 And from there we're going to provide a final output.

551
00:39:16,280 --> 00:39:22,280
 Super simple. So when we go back what we're going to do is we're going to

552
00:39:22,280 --> 00:39:26,040
 start with the router. So we're going to

553
00:39:26,040 --> 00:39:30,760
 obtain the classification either jokes or web search.

554
00:39:30,760 --> 00:39:35,560
 Then we're going to, based on that, we're going to select the appropriate agent

555
00:39:35,560 --> 00:39:39,000
 and the output is going to be the execution of that agent.

556
00:39:39,000 --> 00:39:45,320
 That's it. Super simple. Super easy. And we were able to reproduce without having

557
00:39:45,320 --> 00:39:49,560
 to use external framework or anything like that this

558
00:39:49,560 --> 00:39:53,880
 agentic workflow using plain Python code and the LLM API.

559
00:39:53,880 --> 00:39:58,120
 We're now using the OpenAI agents SDK. We're now using an agentic framework.

560
00:39:58,120 --> 00:40:01,160
 We're building everything ourselves to understand

561
00:40:01,160 --> 00:40:06,120
 under the hood what's going on with these agents or agentic workflows.

562
00:40:06,120 --> 00:40:11,960
 So now that we did that we can run this code.

563
00:40:11,960 --> 00:40:15,400
 And now we're going to make some tests. So the first one is going to be about

564
00:40:15,400 --> 00:40:19,720
 jokes. So pretty simple. Let's see if this works.

565
00:40:19,720 --> 00:40:24,440
 We're going to run it. So this is just tell me a joke about AI.

566
00:40:24,440 --> 00:40:28,280
 Perfect. It works perfectly. So as you can see

567
00:40:28,280 --> 00:40:33,320
 it created a joke. Now let's look at something that involves

568
00:40:33,320 --> 00:40:36,920
 writing the jokes but then also writing the file.

569
00:40:36,920 --> 00:40:40,680
 So that means that two actions have to be executed.

570
00:40:40,680 --> 00:40:45,880
 So let's see what happens here. All right, perfect. We can see that two iterations

571
00:40:45,880 --> 00:40:50,360
 were needed for this agent to finish and it seemed to have created the

572
00:40:50,360 --> 00:40:55,240
 the right file so we can take a look. Perfect. So it created five jokes, saved

573
00:40:55,240 --> 00:40:59,080
 them to file. Beautiful. Final test we're going to do

574
00:40:59,080 --> 00:41:03,000
 is the input for the web search agent. So we're going to research the latest

575
00:41:03,000 --> 00:41:06,280
 papers from 2025 about building agentic workflows.

576
00:41:06,280 --> 00:41:10,600
 And we're going to save that to a file called agentic workflows

577
00:41:10,600 --> 00:41:15,400
 25 summary. So now we're going to test this input

578
00:41:15,400 --> 00:41:18,440
 on our workflow and we're going to see if this works.

579
00:41:18,440 --> 00:41:22,440
 All right, so the router output is correct. Web search in the selected

580
00:41:22,440 --> 00:41:25,800
 agent was the web search agent so everything is working so far.

581
00:41:25,800 --> 00:41:29,880
 All right, perfect. We're done running. It took like a minute 13 seconds

582
00:41:29,880 --> 00:41:33,800
 but it seems like it searched the web and it saved to a file.

583
00:41:33,800 --> 00:41:39,000
 So we're going to look for that file. Beautiful. Look at that.

584
00:41:39,000 --> 00:41:43,320
 It looked, created a very nice report, has a bunch of papers.

585
00:41:43,320 --> 00:41:49,640
 I'm pretty certain that everything worked out and if I wasn't I could

586
00:41:49,640 --> 00:41:53,640
 inspect the intermediary outputs of this function.

587
00:41:53,640 --> 00:41:57,240
 But for now that's it. So today in this video you've learned

588
00:41:57,240 --> 00:42:00,520
 like eight levels of complexity to get to an

589
00:42:00,520 --> 00:42:04,520
 agentic workflow that uses an agent just as a step in a more complex

590
00:42:04,520 --> 00:42:09,480
 hybrid workflow. We've talked about LM calling, chaining,

591
00:42:09,480 --> 00:42:13,000
 routing, all the way up to agents and agentic workflows.

592
00:42:13,000 --> 00:42:15,800
 We've tried to do everything kind of from scratch

593
00:42:15,800 --> 00:42:19,320
 so that you understand the mechanics of function calling, structured outputs,

594
00:42:19,320 --> 00:42:23,480
 routing patterns, and things like that. I think those topics are really important

595
00:42:23,480 --> 00:42:28,360
 if you want to understand how to build off awesome agentic workflows.

596
00:42:28,360 --> 00:42:32,040
 And on an upcoming video I want to tackle from scratch as well.

597
00:42:32,040 --> 00:42:36,040
 Things like evaluation and making these systems work.

598
00:42:36,040 --> 00:42:39,160
 And I'll see you there. Thanks for watching. Don't forget to like and

599
00:42:39,160 --> 00:42:43,480
 subscribe and see you next time. Cheers.

